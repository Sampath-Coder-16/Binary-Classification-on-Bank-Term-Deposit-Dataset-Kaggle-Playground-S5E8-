# -*- coding: utf-8 -*-
"""binaryclassificationkaggle.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bdqyl6_OLVc-_d2h2heaqtpxDqOnpWX2

Binary Classification with a Bank Dataset

MY Goal: MY goal is to predict whether a client will subscribe to a bank term deposit.

Target column ("y"): binary 0/1
"""

import pandas as pd
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Load your datasets
train_df = pd.read_csv('train.csv')
test_df = pd.read_csv('test.csv')

# Explore the training data
print("Training data info:")
display(train_df.info())

print("\nTraining data head:")
display(train_df.head())

print("\nTraining data description:")
display(train_df.describe())

# Check for missing values
print("\nMissing values in train_df:")
display(train_df.isnull().sum())

print("\nMissing values in test_df:")
display(test_df.isnull().sum())

# Explore the test data
print("\nTest data info:")
display(test_df.info())

print("\nTest data head:")
display(test_df.head())

print("\nTest data description:")
display(test_df.describe())

# Check the distribution of the target variable 'y' in the training data
print("\nDistribution of target variable 'y' in train_df:")
display(train_df['y'].value_counts())

# Display the proportion of the target variable 'y'
print("\nProportion of target variable 'y' in train_df:")
display(train_df['y'].value_counts(normalize=True))

# Handle missing values by dropping rows with any missing values
# This is a simple approach, consider other imputation methods if needed
train_df.dropna(inplace=True)
test_df.dropna(inplace=True)

# Check for missing values
print("\nMissing values in train_df:")
display(train_df.isnull().sum())

print("\nMissing values in test_df:")
display(test_df.isnull().sum())

# Separate target variable from features
X_train = train_df.drop(['id', 'y'], axis=1)
y_train = train_df['y']
X_test = test_df.drop('id', axis=1)

# Identify categorical and numerical features
categorical_features = X_train.select_dtypes(include=['object']).columns
numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns

# Create preprocessing pipelines for numerical and categorical features
numerical_transformer = StandardScaler()
categorical_transformer = OneHotEncoder(handle_unknown='ignore')

# Create a column transformer to apply different transformations to different columns
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_features),
        ('cat', categorical_transformer, categorical_features)
    ])

# Create a preprocessing pipeline
preprocess_pipeline = Pipeline(steps=[('preprocessor', preprocessor)])

# Apply preprocessing to the training and testing data
X_train_processed = preprocess_pipeline.fit_transform(X_train)
X_test_processed = preprocess_pipeline.transform(X_test)

print("Shape of processed training data:", X_train_processed.shape)
print("Shape of processed testing data:", X_test_processed.shape)

"""Train and evaluate LogisticRegression


Train a LogisticRegression Classifier, evaluate its performance using cross-validation, generate predictions on the test set, and save the predictions to a CSV file.

"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import StratifiedKFold, cross_val_score

# Pipeline for preprocessing and model
# Using the preprocessor defined in the previous step
pipe = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression(max_iter=1000))
])

# Stratified k-fold cross-validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = cross_val_score(pipe, X_train, y_train, cv=cv, scoring='roc_auc')

print(f'Logistic Regression CV AUC scores: {cv_scores}')
print(f'Mean CV AUC score: {cv_scores.mean():.4f}')

# Train model on full data
pipe.fit(X_train, y_train)

# Generate predictions on test set
y_pred = pipe.predict_proba(X_test)[:, 1]  # Probability for class 1

# Prepare submission
submission = pd.DataFrame({'id': test_df['id'], 'prediction': y_pred})
submission.to_csv('submission.csv', index=False)

# Train model on full data
pipe.fit(X_train, y_train)

# Generate predictions on test set
y_pred = pipe.predict_proba(X_test)[:, 1]  # Probability for class 1

# Prepare submission
submission = pd.DataFrame({'id': test_df['id'], 'prediction': y_pred})
submission.to_csv('submission.csv', index=False)

print("\nSubmission file created successfully!")
display(submission)

# Save the submission DataFrame to an Excel file
submission.to_excel('submission.xlsx', index=False)

print("\nSubmission file saved as submission.xlsx")

display(submission)

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8, 6))
sns.histplot(submission['prediction'], bins=50, kde=True)
plt.title('Distribution of Predicted Probabilities')
plt.xlabel('Predicted Probability of Subscribing (y=1)')
plt.ylabel('Frequency')
plt.show()

"""Train and evaluate random forest


Train a Random Forest Classifier, evaluate its performance using cross-validation, generate predictions on the test set, and save the predictions to a CSV file.

The task is to train a Random Forest Classifier, evaluate it using cross-validation, make predictions, and save them. This requires importing the necessary model, creating a pipeline including the preprocessor, performing cross-validation, training the model on the full training data, generating predictions, and saving the results to a CSV file. These steps can be efficiently grouped into a single code block.
"""

from sklearn.ensemble import RandomForestClassifier

# Pipeline for preprocessing and Random Forest model
rf_pipe = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))
])

# Stratified k-fold cross-validation for Random Forest
cv_rf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cv_scores_rf = cross_val_score(rf_pipe, X_train, y_train, cv=cv_rf, scoring='roc_auc')

print(f'Random Forest CV AUC scores: {cv_scores_rf}')
print(f'Mean CV AUC score for Random Forest: {cv_scores_rf.mean():.4f}')

# Train the Random Forest model on the full training data
rf_pipe.fit(X_train, y_train)

# Generate predictions on the test set (probabilities for class 1)
y_pred_rf = rf_pipe.predict_proba(X_test)[:, 1]

# Prepare submission DataFrame
submission_rf = pd.DataFrame({'id': test_df['id'], 'prediction': y_pred_rf})

# Save the submission DataFrame to a CSV file
submission_rf.to_csv('submission_rf.csv', index=False)

print("\nRandom Forest submission file 'submission_rf.csv' created successfully!")

"""Train and evaluate gradient boosting (lightgbm)
task:
Train a LightGBM Classifier, evaluate its performance using cross-validation, generate predictions on the test set, and save the predictions to a CSV file.

Import the necessary library and create a pipeline for the LightGBM model, then perform cross-validation.
"""

from lightgbm import LGBMClassifier
from sklearn.model_selection import StratifiedKFold, cross_val_score

# Pipeline for preprocessing and LightGBM model
lgbm_pipe = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LGBMClassifier(random_state=42))
])

# Stratified k-fold cross-validation for LightGBM
cv_lgbm = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cv_scores_lgbm = cross_val_score(lgbm_pipe, X_train, y_train, cv=cv_lgbm, scoring='roc_auc')

print(f'LightGBM CV AUC scores: {cv_scores_lgbm}')
print(f'Mean CV AUC score for LightGBM: {cv_scores_lgbm.mean():.4f}')

"""
Train the LightGBM pipeline on the full training data, generate predictions on the test set, create the submission DataFrame, and save it to a CSV file.

"""

# Train the LightGBM model on the full training data
lgbm_pipe.fit(X_train, y_train)

# Generate predictions on the test set (probabilities for class 1)
y_pred_lgbm = lgbm_pipe.predict_proba(X_test)[:, 1]

# Prepare submission DataFrame
submission_lgbm = pd.DataFrame({'id': test_df['id'], 'prediction': y_pred_lgbm})

# Save the submission DataFrame to a CSV file
submission_lgbm.to_csv('submission_lgbm.csv', index=False)

print("\nLightGBM submission file 'submission_lgbm.csv' created successfully!")

"""Train and evaluate support vector machine (svm)
task:
Train an SVM Classifier, evaluate its performance using cross-validation, generate predictions on the test set, and save the predictions to a CSV file.

Import the SVC class and create a pipeline for the SVM classifier, then perform cross-validation and print the scores.
"""

from sklearn.svm import SVC

# Pipeline for preprocessing and SVM model
svm_pipe = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', SVC(probability=True, random_state=42))
])

# Stratified k-fold cross-validation for SVM
cv_svm = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cv_scores_svm = cross_val_score(svm_pipe, X_train, y_train, cv=cv_svm, scoring='roc_auc')

print(f'SVM CV AUC scores: {cv_scores_svm}')
print(f'Mean CV AUC score for SVM: {cv_scores_svm.mean():.4f}')

# Train the SVM model on the full training data
svm_pipe.fit(X_train, y_train)

# Generate predictions on the test set (probabilities for class 1)
y_pred_svm = svm_pipe.predict_proba(X_test)[:, 1]

# Prepare submission DataFrame
submission_svm = pd.DataFrame({'id': test_df['id'], 'prediction': y_pred_svm})

# Save the submission DataFrame to a CSV file
submission_svm.to_csv('submission_svm.csv', index=False)

print("\nSVM submission file 'submission_svm.csv' created successfully!")

"""Train and evaluate k-nearest neighbors (knn)

task:
Train a KNN Classifier, evaluate its performance using cross-validation, generate predictions on the test set, and save the predictions to a CSV file.

Import the KNeighborsClassifier and create a pipeline for the KNN classifier, then perform cross-validation and print the scores. Train the model on the full training data, generate predictions, create the submission DataFrame, and save it to a CSV file.
"""

from sklearn.neighbors import KNeighborsClassifier

# Pipeline for preprocessing and KNN model
knn_pipe = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', KNeighborsClassifier())
])

# Stratified k-fold cross-validation for KNN
cv_knn = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cv_scores_knn = cross_val_score(knn_pipe, X_train, y_train, cv=cv_knn, scoring='roc_auc')

print(f'KNN CV AUC scores: {cv_scores_knn}')
print(f'Mean CV AUC score for KNN: {cv_scores_knn.mean():.4f}')

# Train the KNN model on the full training data
knn_pipe.fit(X_train, y_train)

# Generate predictions on the test set (probabilities for class 1)
y_pred_knn = knn_pipe.predict_proba(X_test)[:, 1]

# Prepare submission DataFrame
submission_knn = pd.DataFrame({'id': test_df['id'], 'prediction': y_pred_knn})

# Save the submission DataFrame to a CSV file
submission_knn.to_csv('submission_knn.csv', index=False)

print("\nKNN submission file 'submission_knn.csv' created successfully!")

"""## Train and evaluate Naive Bayes

### Subtask:
Train a Naive Bayes Classifier, evaluate its performance using cross-validation, generate predictions on the test set, and save the predictions to a CSV file.

Import the necessary library and create a pipeline for the Naive Bayes classifier, then perform cross-validation and print the scores. Train the model on the full training data, generate predictions, create the submission DataFrame, and save it to a CSV file.
"""

from sklearn.naive_bayes import GaussianNB

# Pipeline for preprocessing and Naive Bayes model
nb_pipe = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', GaussianNB())
])

# Stratified k-fold cross-validation for Naive Bayes
cv_nb = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cv_scores_nb = cross_val_score(nb_pipe, X_train, y_train, cv=cv_nb, scoring='roc_auc')

print(f'Naive Bayes CV AUC scores: {cv_scores_nb}')
print(f'Mean CV AUC score for Naive Bayes: {cv_scores_nb.mean():.4f}')

# Train the Naive Bayes model on the full training data
nb_pipe.fit(X_train, y_train)

# Generate predictions on the test set (probabilities for class 1)
y_pred_nb = nb_pipe.predict_proba(X_test)[:, 1]

# Prepare submission DataFrame
submission_nb = pd.DataFrame({'id': test_df['id'], 'prediction': y_pred_nb})

# Save the submission DataFrame to a CSV file
submission_nb.to_csv('submission_nb.csv', index=False)

print("\nNaive Bayes submission file 'submission_nb.csv' created successfully!")

# Display the head of the Naive Bayes submission DataFrame
print("Head of Naive Bayes Submission DataFrame:")
display(submission_nb.head())

"""## Generate AUC Curves

Generate and plot the ROC curves for all trained models and display their AUC scores.
"""

from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt

# Train each model on the full training data and get predicted probabilities
pipe.fit(X_train, y_train)
y_train_pred_lr = pipe.predict_proba(X_train)[:, 1]

rf_pipe.fit(X_train, y_train)
y_train_pred_rf = rf_pipe.predict_proba(X_train)[:, 1]

lgbm_pipe.fit(X_train, y_train)
y_train_pred_lgbm = lgbm_pipe.predict_proba(X_train)[:, 1]

svm_pipe.fit(X_train, y_train)
y_train_pred_svm = svm_pipe.predict_proba(X_train)[:, 1]

knn_pipe.fit(X_train, y_train)
y_train_pred_knn = knn_pipe.predict_proba(X_train)[:, 1]

nb_pipe.fit(X_train, y_train)
y_train_pred_nb = nb_pipe.predict_proba(X_train)[:, 1]


# Calculate ROC curve and AUC for each model
fpr_lr, tpr_lr, _ = roc_curve(y_train, y_train_pred_lr)
auc_lr = roc_auc_score(y_train, y_train_pred_lr)

fpr_rf, tpr_rf, _ = roc_curve(y_train, y_train_pred_rf)
auc_rf = roc_auc_score(y_train, y_train_pred_rf)

fpr_lgbm, tpr_lgbm, _ = roc_curve(y_train, y_train_pred_lgbm)
auc_lgbm = roc_auc_score(y_train, y_train_pred_lgbm)

fpr_svm, tpr_svm, _ = roc_curve(y_train, y_train_pred_svm)
auc_svm = roc_auc_score(y_train, y_train_pred_svm)

fpr_knn, tpr_knn, _ = roc_curve(y_train, y_train_pred_knn)
auc_knn = roc_auc_score(y_train, y_train_pred_knn)

fpr_nb, tpr_nb, _ = roc_curve(y_train, y_train_pred_nb)
auc_nb = roc_auc_score(y_train, y_train_pred_nb)


# Plot ROC curves
plt.figure(figsize=(10, 8))
plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {auc_lr:.4f})')
plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {auc_rf:.4f})')
plt.plot(fpr_lgbm, tpr_lgbm, label=f'LightGBM (AUC = {auc_lgbm:.4f})')
plt.plot(fpr_svm, tpr_svm, label=f'SVM (AUC = {auc_svm:.4f})')
plt.plot(fpr_knn, tpr_knn, label=f'KNN (AUC = {auc_knn:.4f})')
plt.plot(fpr_nb, tpr_nb, label=f'Naive Bayes (AUC = {auc_nb:.4f})')


plt.plot([0, 1], [0, 1], 'k--', label='Random Guessing')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves for Different Models')
plt.legend()
plt.grid(True)
plt.show()

"""## Create Combined Submission File

Combine the predictions from all trained models into a single CSV file.
"""

# Merge submission files
combined_submission = submission.rename(columns={'prediction': 'prediction_lr'})
combined_submission = combined_submission.merge(submission_rf.rename(columns={'prediction': 'prediction_rf'}), on='id')
combined_submission = combined_submission.merge(submission_lgbm.rename(columns={'prediction': 'prediction_lgbm'}), on='id')
combined_submission = combined_submission.merge(submission_svm.rename(columns={'prediction': 'prediction_svm'}), on='id')
combined_submission = combined_submission.merge(submission_knn.rename(columns={'prediction': 'prediction_knn'}), on='id')
combined_submission = combined_submission.merge(submission_nb.rename(columns={'prediction': 'prediction_nb'}), on='id')


# Save the combined submission file
combined_submission.to_csv('combined_submission.csv', index=False)

print("\nCombined submission file 'combined_submission.csv' created successfully!")
display(combined_submission.head())

